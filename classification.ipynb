{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1f9abd9-2e8b-40fb-995a-623d46790162",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2' # 디버그 메시지 끄기\n",
    "import tensorflow as tf\n",
    "# gpu 사용 확인\n",
    "print(tf.test.gpu_device_name())\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, Embedding, Dropout\n",
    "import matplotlib.pyplot as plt # 데이터 시각화\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "import pickle\n",
    "\n",
    "import natsort\n",
    "import json\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from angle_out import out\n",
    "import numpy as np\n",
    "\n",
    "# tf.keras.backend.clear_session()\n",
    "\n",
    "def lstm():\n",
    "    model = keras.Sequential()\n",
    "    model.add(layers.LSTM(4, activation='relu', input_shape=(4, 1), return_sequences=True))\n",
    "    model.add(layers.Dropout(0.2))\n",
    "    model.add(layers.LSTM(14, activation='relu', return_sequences=False))\n",
    "    # model.add(layers.Dense(16, activation='relu'))\n",
    "    model.add(layers.Dense(3, activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def random_forest(n_estimators =100, max_depth=10, min_samples_split=2, random_state=0):\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, min_samples_split=min_samples_split, random_state=random_state)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be4b1f67-711d-4463-8651-e9354d772892",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/BODYLOWER > \n",
      "./data/BODYSCRATCH > \n",
      "./data/BODYSHAKE > \n",
      "./data/FOOTUP > \n",
      "./data/HEADING > \n",
      "./data/LYING > \n",
      "./data/MOUNTING > \n",
      "./data/SIT > \n",
      "./data/TURN > \n",
      "data sample > [[-147.8194641 ]\n",
      " [ -36.73434893]\n",
      " [ -36.73434893]\n",
      " [  34.88673866]]\n",
      "x shape > (213130, 4, 1)\n",
      "y shape > (213130,)\n"
     ]
    }
   ],
   "source": [
    "# meta_data = []\n",
    "data = []\n",
    "label = []\n",
    "window = 4\n",
    "\n",
    "path = \"./data\"\n",
    "label_path = \"./label\"\n",
    "\n",
    "\n",
    "# body_parts = {\n",
    "#     '1' : '코',\n",
    "#     '2' : '이마 정 중앙',\n",
    "#     '3' : '입꼬리(입끝)',\n",
    "#     '4' : '아래 입술 중앙',\n",
    "#     '5' : '목',\n",
    "#     '6' : '앞다리 오른쪽 시작',\n",
    "#     '7' : '앞다리 왼쪽 시작',\n",
    "#     '8' : '앞다리 오른쪽 발목',\n",
    "#     '9' : '앞다리 왼쪽 발목',\n",
    "#     '10' : '오른쪽 대퇴골',\n",
    "#     '11' : '왼쪽 대퇴골',\n",
    "#     '12' : '뒷다리 오른쪽 발목',\n",
    "#     '13' : '뒷다리 왼쪽 발목',\n",
    "#     '14' : '꼬리 시작',\n",
    "#     '15' : '꼬리 끝',\n",
    "# }\n",
    "\n",
    "keypoint = [\n",
    "    \"nose\",\n",
    "    \"forehead\",\n",
    "    \"mouth\",\n",
    "    \"under_mouth\",\n",
    "    \"neck\",\n",
    "    \"right_front_start\",\n",
    "    \"left_front_start\",\n",
    "    \"right_front_ankle\",\n",
    "    \"left_front_ankle\",\n",
    "    \"right_thigh\",\n",
    "    \"left_thigh\",\n",
    "    \"right_back_ankle\",\n",
    "    \"left_back_ankle\",\n",
    "    \"tail_start\",\n",
    "    \"tail_end\"\n",
    "]\n",
    "\n",
    "# label_link = {\n",
    "#     '1' : [1, 2, 5, 14, 15],\n",
    "#     '2' : [5, 6, 8],\n",
    "#     '3' : [5, 7, 9],\n",
    "#     '4' : [14, 10, 12],\n",
    "#     '5' : [14, 11, 13],\n",
    "# }\n",
    "\n",
    "label_parts = [\n",
    "    [\"under_mouth\", \"nose\", \"forehead\", \"neck\"],\n",
    "    [\"nose\", \"forehead\", \"neck\", \"tail_start\"],\n",
    "    [\"forehead\", \"neck\", \"tail_start\", \"tail_end\"],\n",
    "    [\"forehead\", \"neck\", \"right_front_start\", \"right_front_ankle\"],\n",
    "    [\"forehead\", \"neck\", \"left_front_start\", \"left_front_ankle\"],\n",
    "    [\"neck\", \"tail_start\", \"right_thigh\", \"right_back_ankle\"],\n",
    "    [\"neck\", \"tail_start\", \"left_thigh\", \"left_back_ankle\"],\n",
    "]\n",
    "\n",
    "iii = 0\n",
    "\n",
    "# print(\"data\")\n",
    "\n",
    "for data_list in natsort.natsorted(os.listdir(path)):\n",
    "    if data_list == \"TEST\":\n",
    "        continue\n",
    "    elif \"_DLC\" in data_list:\n",
    "        continue \n",
    "    elif \"_bak\" in data_list:\n",
    "        continue\n",
    "    elif not os.path.isdir(f\"{path}/{data_list}\"):\n",
    "        continue\n",
    "    print(f\"{path}/{data_list} > \")\n",
    "        \n",
    "    delta = f\"{path}/{data_list}\"\n",
    "    for label_list in natsort.natsorted(os.listdir(delta)):\n",
    "        iii += 1\n",
    "        # _json_ = label_list\n",
    "        # delta_np = f\"{delta}/{delta_list}/{delta_list}.npy\"\n",
    "        delta_label = f\"{label_path}/{data_list}/{label_list}.json\"\n",
    "        # delta_label = f\"{delta}/{delta_list}/{delta_list}.json\"\n",
    "        \n",
    "        # print(f\"{delta_label} > \")\n",
    "        \n",
    "        keypoints = []\n",
    "        \n",
    "        if not os.path.exists(delta_label):\n",
    "            continue\n",
    "        \n",
    "        with open(delta_label, \"r\") as label_json:\n",
    "            label_tmp = json.load(label_json)\n",
    "            for annotation in label_tmp['annotations']:\n",
    "                # frame = annotation['frame_number']\n",
    "                # timestamp = annotation['timestamp']\n",
    "                key = annotation['keypoints']\n",
    "                # print(keypoint)\n",
    "                # if keypoint == None:\n",
    "                    # keypoint['x'] = 0\n",
    "                    # keypoint['y'] = 0\n",
    "                # print(annotation['keypoints'])\n",
    "                # if None in key:\n",
    "                # print(key)\n",
    "                for val in key:\n",
    "                    # print(val)\n",
    "                    if key[val] == None:\n",
    "                        key[val] = {'x' : 0 , 'y' : 0}\n",
    "                keypoints.append(key)\n",
    "                # print(keypoints) \n",
    "            # x_tmp = json.load(label_json)[\"annotations\"][][\"keypoints\"]\n",
    "            \n",
    "        # print(len(data))\n",
    "        # print(len(label))\n",
    "        # print(label_tmp)\n",
    "    \n",
    "                \n",
    "        # np_tmp = np.load(delta_np)\n",
    "        tmp = np.array(keypoints)\n",
    "        # print(tmp[0])\n",
    "        \n",
    "        # print(tmp[0].shape)\n",
    "        meta_data = []\n",
    "        # angle_arr = []\n",
    "        for data_index in tmp:\n",
    "            # print(data_index)\n",
    "            data_tmp = []\n",
    "            for index in data_index:\n",
    "                # print(data_index[index])\n",
    "                data_tmp.append(data_index[index])\n",
    "            # angle = out(inputs = data_index, keypoint= keypoint, label_parts = label_parts)\n",
    "            # angle_arr.append(angle)\n",
    "        meta_data.append(np.array(data_tmp))\n",
    "            # print(data_tmp)\n",
    "        \n",
    "        angle_arr = []\n",
    "        # print(meta_data)\n",
    "        for i in range(len(meta_data)):\n",
    "            angle = out(inputs = meta_data[i], keypoint= keypoint, label_parts = label_parts)\n",
    "            angle_arr.append(angle)\n",
    "        \n",
    "        # print(angle_arr)\n",
    "        # print(f\"window {window}\")\n",
    "        # print(f\"len {len(meta_data)}\")\n",
    "        # print(f\"data > {meta_data[0]}\")\n",
    "        # print(f\"angle > {angle_arr}\")\n",
    "        np_tmp = []\n",
    "        for index in range(window,len(angle_arr[0])):\n",
    "            tmp_wind = angle_arr[0][index-window:index]\n",
    "            \n",
    "            data.append(tmp_wind)\n",
    "            np_tmp.append(tmp_wind)\n",
    "            label.append(data_list)\n",
    "        \n",
    "        np_save = f\"{label_path}/{data_list}/{label_list}.npy\"\n",
    "        np.save(np_save, np_tmp)\n",
    "        # label.append(data_list)\n",
    "            \n",
    "            \n",
    "# print(f\"count = {iii}\")\n",
    "            \n",
    "# print(f\" {len(data)}\")\n",
    "# print(len(label))\n",
    "\n",
    "# angle_arr = []\n",
    "# data_t = []\n",
    "\n",
    "\n",
    "    # print(meta_data[index])\n",
    "    # print(label[index])\n",
    "    # for i in range(len(data[index])):\n",
    "    # print(data[index])\n",
    "        # angle = out(inputs = meta_data[index], keypoint= keypoint, label_parts = label_parts)\n",
    "        # data_t.append(angle)\n",
    "    \n",
    "    # for index in range(window,len(np_tmp)):\n",
    "    #     data.append(angle_arr[index-window:index])\n",
    "    #     label.append(label_tmp)\n",
    "    \n",
    "# print(f\"shape > {np.shape(data)}\")\n",
    "print(f\"data sample > {data[0]}\")\n",
    "        # angle_arr = []\n",
    "        # for i in range(len(np_tmp)):\n",
    "        #     angle = out(inputs = np_tmp[i])\n",
    "        #     angle_arr.append(angle)\n",
    "\n",
    "        #     for index in range(window,len(np_tmp)):\n",
    "        #         data.append(angle_arr[index-window:index])\n",
    "        #         label.append(label_tmp)\n",
    "\n",
    "# print(np.shape(data))\n",
    "x_train = np.array(data)\n",
    "# x_train = x_train.reshape(-1,4,10)\n",
    "y_train = np.array(label)\n",
    "\n",
    "print(f\"x shape > {x_train.shape}\")\n",
    "print(f\"y shape > {y_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b0373161-10a5-425e-a30d-e79eb7eb1849",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213130,)\n"
     ]
    }
   ],
   "source": [
    "word_to_index = {\"BODYLOWER\" : 0, \"BODYSCRATCH\" : 1, \"BODYSHAKE\" : 2, \"FOOTUP\" : 3, \"HEADING\" : 4, \"LYING\" : 5, \"MOUNTING\" : 6, \"SIT\" : 7, \"TURN\" : 8}\n",
    "\n",
    "def convert_word_to_index(word_to_index, sentences):\n",
    "    arr = []\n",
    "    for i in range(len(sentences)):\n",
    "        arr.append(word_to_index[sentences[i]])\n",
    "    arr = np.array(arr)\n",
    "    return arr\n",
    "    \n",
    "def one_hot_encoding(words, word_to_index):\n",
    "    ohv = []\n",
    "    for word in words:\n",
    "        one_hot_vector = [0]*(len(word_to_index))\n",
    "        index = word_to_index[word]\n",
    "        one_hot_vector[index] = 1\n",
    "        ohv.append([one_hot_vector])\n",
    "    ret = np.array(ohv)\n",
    "    return ret\n",
    "\n",
    "\n",
    "# y_tmp = tf.one_hot(y_train, 3, on_value=1.0, off_value=0.0)\n",
    "\n",
    "# y_tmp = one_hot_encoding(y_train, word_to_index)\n",
    "y_tmp = convert_word_to_index(word_to_index, y_train)\n",
    "# y_tmp = y_tmp.reshape(-1,1,3)\n",
    "\n",
    "# print(y_train.shape)\n",
    "print(y_tmp.shape)\n",
    "# print(x_train[0])\n",
    "# print(y_tmp[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "075806f0-5175-473a-b6f4-4605705e4ad4",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(213130, 4) (213130,)\n",
      "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 45, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 25, 'n_jobs': None, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "# np_data = np.load('./out/coco_train02.npy')\n",
    "# print(np_data.shape)\n",
    "# print(np_data[19])\n",
    "# print(data[0])\n",
    "\n",
    "# window = 4\n",
    "# arr =[]\n",
    " \n",
    "# model = lstm()\n",
    "max_depth = 45\n",
    "n_estimators = 25\n",
    "model = random_forest(max_depth=max_depth, n_estimators=n_estimators, random_state=0)\n",
    "# model.compile(loss='binary_crossentropy',\n",
    "            #   optimizer='rmsprop',\n",
    "            #   metrics=['accuracy'])\n",
    "# model.compile(loss='mse', optimizer=Adam(0.01))\n",
    "\n",
    "# print(model.summary())\n",
    "\n",
    "\n",
    "# x_train=np.array(x_train) # (16,4,5,2) -> (16,4,10,1)\n",
    "\n",
    "# x_train = x_train.reshape(-1, x_train.shape[1],x_train.shape[2], 1)\n",
    "x_train = x_train.reshape(-1, 4)\n",
    "\n",
    "print(x_train.shape, y_tmp.shape)\n",
    "# print(x_train[0])\n",
    "# print(y_tmp[0])\n",
    "\n",
    "model.fit(x_train, y_tmp)\n",
    "# model.fit(x_train, y_tmp, batch_size=1 , epochs=40, verbose=1)\n",
    "\n",
    "model_params = model.get_params()\n",
    "print(model_params)\n",
    "\n",
    "pickle.dump(model, open(f\"./model/random_forest/{max_depth}_{n_estimators}.pkl\", 'wb'))\n",
    "# model.save('lstm_model.h5')\n",
    "# model.save\n",
    "# print(\"모델 저장 완려\") #려~\n",
    "\n",
    "# pred = model.predict(x_train) # 테스트 데이터 예측\n",
    "\n",
    "# fig = plt.figure(facecolor='white')\n",
    "# ax = fig.add_subplot(111)\n",
    "# ax.plot(y_train, label='True')\n",
    "# ax.plot(pred, label='Prediction')\n",
    "# ax.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06a43e7c-a5b6-4efb-a241-e42565a02c38",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score > 0.9976680898981842\n",
      "model accuracy score > 0.9976680898981842\n",
      "predict time > 0.0018527507781982422\n"
     ]
    }
   ],
   "source": [
    "# with open(delta_label, \"r\") as label_json:\n",
    "    # label_tmp = json.load(label_json)[0][\"pose\"]\n",
    "    \n",
    "# model = keras.models.load_model('lstm_model.h5')\n",
    "# lenght = len(x_train)\n",
    "# faild = 0\n",
    "# fail_list = []\n",
    "# for i in tqdm(range(lenght), desc=f\"오차 {faild/lenght}\", mininterval=1):\n",
    "#     x_tmp = [x_train[i]]\n",
    "#     y_pred = model.predict(x_tmp)\n",
    "#     if y_pred != y_tmp[i]:\n",
    "#         faild += 1\n",
    "#         print(f\"실패 > {faild}/{i}\")\n",
    "#         fail_list.append(i)\n",
    "\n",
    "# print(f\"성공률 > {(1-faild/lenght)*100}\")\n",
    "\n",
    "score = model.score(x_train, y_tmp)\n",
    "\n",
    "print(f\"score > {score}\")\n",
    "print(f\"model accuracy score > {accuracy_score(y_tmp, model.predict(x_train))}\")\n",
    "\n",
    "import time\n",
    "\n",
    "start = time.time()\n",
    "y_pred = model.predict([x_train[0]])\n",
    "# model.\n",
    "run_time = time.time() - start\n",
    "print(f\"predict time > {run_time}\")\n",
    "\n",
    "params = model.get_params()\n",
    "\n",
    "params[\"score\"] = score\n",
    "params[\"pred_time\"] = run_time\n",
    "# json_data = json.dumps(params)\n",
    "with open(f\"./model/depth_{max_depth}_{n_estimators}.json\", \"w\") as json_file:\n",
    "    json.dump(params, json_file)\n",
    "# print(f\"실패한 갯수 > {faild/len(x_train)}\")\n",
    "# print(f\"{x_train[0]}\")\n",
    "\n",
    "\n",
    "# y_pred = model.predict(x_tmp)\n",
    "# print(f\"예상치 > {y_pred}\")\n",
    "# print(f\"실제값 > {y_tmp[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6feab874",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DLC",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
