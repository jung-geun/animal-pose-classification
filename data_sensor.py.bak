# 동영상을 입력으로하며, 학습된 모델을 이용하여 프레임 단위로 분석하고 예측한 관절 좌표를 생성 및 저장한다.

import deeplabcut
import os
import cv2 
import yaml
import numpy as np
from tqdm import tqdm
from skimage.util import img_as_ubyte
from deeplabcut.utils import auxiliaryfunctions
from deeplabcut.utils.auxfun_videos import imread
from deeplabcut.pose_estimation_tensorflow.core import predict
# os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

"""
 ----- param -----
 src_file_path : 분석할 동영상 파일 
 config_path : 학습된 모델의 yaml 파일 = dlc_cfg
 cfg_path : DLC 프로젝트의 yaml 파일 = cfg
 ----- pose_cfg.yaml에 추가 -----
init_weights: "/drive/<my_project>/dlc-models/iteration-0/<folder>/train/snapshot-#"
mean_pixel: [123.68, 116.779, 103.939]
weight_decay: 0.0001
pairwise_predict: False
partaffinityfield_predict: False
stride: 8.0
intermediate_supervision: False
dataset_type: imgaug
"""



""" edit. 폴더명 파라미터로 받아서 실행하기
"""
def ini_DLC(config_path="./label1/dlc-models/iteration-0/label1Dec21-trainset95shuffle1/test/pose_cfg.yaml",
            cfg_path="./label1/config.yaml"):
    with open(config_path) as f:
        dlc_cfg = yaml.full_load(f)      # 학습된 모델의 yaml 데이터
    with open(cfg_path) as f:
        cfg = yaml.full_load(f)      # 프로젝트의 yaml 데이터
    try :
        batchsize = dlc_cfg["batch_size"]
    except :
        # update batchsize (based on parameters in config.yaml)
        dlc_cfg["batch_size"] = cfg["batch_size"]
        batchsize = dlc_cfg["batch_size"]

    return  dlc_cfg,cfg,batchsize



def get_img_coord(src_img,dlc_cfg,cfg,batchsize):
    #print("img_ : ",src_img.shape) # (360, 640, 3)
    im = src_img
    
    sess, inputs, outputs = predict.setup_pose_prediction(dlc_cfg)
    
    ny, nx, nc = np.shape(im)
    # batch_size에 따라 반복...?
    batch_ind = 0    # keeps track of which image within a batch should be written to
    batch_num = 0    # keeps track of which batch you are at

    # cropping 설정 or batch_size=1일 때를 제외한 나머지 경우
    frames = np.empty((batchsize, ny, nx, 3), dtype="ubyte"      # this keeps all the frames of a batch
    )  
    frames[batch_ind] = img_as_ubyte(im)


    if batch_ind == batchsize - 1:
        pose = predict.getposeNP(frames, dlc_cfg, sess, inputs, outputs)
        # PredictedData[batch_num * batchsize : (batch_num + 1) * batchsize, :]
        # = pose
        batch_ind = 0
        batch_num += 1
    else:
        batch_ind += 1

    if (batch_ind > 0):
        # take care of the last frames (the batch that might have been
        # processed)
        pose = predict.getposeNP(frames, dlc_cfg, sess, inputs, outputs)     # process the whole batch (some frames might be from previous batch!)
        
        # print("getPose : ",type(pose),pose) # <class 'numpy.ndarray'> [[
        # 1.45855195e+02 6.34100614e+01 7.33174324e-01 2.44310002e+02 ...]..]

        count = len(pose[0])  # 63 (point_21 * values_3)
        index = 0
        ans = []
        # coords 값 추출
        while index < count:
            point = [pose[0][index + 0],pose[0][index + 1],pose[0][index + 2]]
            ans.append(point)
            index += 3
        
        ans = np.array(ans)

        return ans 



def analyze_frames(src_avi="coco_train02.mov"):   

    dlc_cfg,cfg,batchsize = ini_DLC()
    data = []
    # Open the AVI file
    cap = cv2.VideoCapture(src_avi)

    # Check if the file was opened successfully
    if not cap.isOpened():
        print("Error opening the file")

    # 진행률 process_bar
    length = cap.get(cv2.CAP_PROP_FRAME_COUNT)      # 분석할 프레임 개수
    # pbar = tqdm(total=length)  
    count = 0 

    # Read frames from the file
    while True:
        # Read a frame
        ret, frame = cap.read()

        # Break if we reached the end of the file
        if not ret:
            break
        # Display the frame
        cv2.imshow("Frame", frame)
        pos = get_img_coord(frame,dlc_cfg,cfg,batchsize)
        #print("mk_from_avi.pos : ",type(pos),pos.shape) # <class
        #'numpy.ndarray'> (21, 3)
        data.append(pos)

        # if count != 0:
            # pbar.update()
        
        # draw points to frame
        for i in range(len(pos)):
            cv2.circle(frame, (int(pos[i][0]), int(pos[i][1])), 3, (0, 0, 255), -1)
            cv2.putText(frame, str(i), (int(pos[i][0]), int(pos[i][1])), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 1)

        # Display the frame
        cv2.imshow("Frame", frame)
        
        #print("count : ",count) # 271 (sec_9 * fps_30)
        if count > length:
            break
        else :
            pass

        count += 1

    # pbar.close()
    # Release the video capture object
    cap.release()

    # Close all the windows
    cv2.destroyAllWindows()

    data = np.array(data)

    return data



def analyze_video():
    src_file_path = './coco_train02.mov'
    data = analyze_frames(src_file_path)
    #print("LB : ",type(data),data.shape) # <class 'numpy.ndarray'> (271, 21, 3)
    np.save(src_file_path,data)

analyze_video()

#def load_npy_data():
#    np_path='./coco_train02.mov.npy'
#    data = np.load(np_path)
#    print(data)
#    pass

#load_npy_data()

 